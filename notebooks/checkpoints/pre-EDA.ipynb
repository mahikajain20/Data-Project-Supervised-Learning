{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- The os module has a perfect method to list files in a directory.\n",
    "- Pandas json normalize could work here but is not necessary to convert the JSON data to a dataframe.\n",
    "- You may need a nested for-loop to access each sale!\n",
    "- We've put a lot of time into creating the structure of this repository, and it's a good example for future projects.  In the file functions_variables.py, there is an example function that you can import and use.  If you have any variables, functions or classes that you want to make, they can be put in the functions_variables.py file and imported into a notebook.  Note that only .py files can be imported into a notebook. If you want to import everything from a .py file, you can use the following:\n",
    "```python\n",
    "from functions_variables import *\n",
    "```\n",
    "If you just import functions_variables, then each object from the file will need to be prepended with \"functions_variables\"\\\n",
    "Using this .py file will keep your notebooks very organized and make it easier to reuse code between notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (this is not an exhaustive list of libraries)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "import json\n",
    "from pprint import pprint\n",
    "from functions_variables import encode_tags, extract_info\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Chnage custom function and jupyter function without restarting kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1977416680.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, newdata], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the directory containing JSON files\n",
    "json_directory = '../data/raw_files/'\n",
    "\n",
    "# Get all JSON file paths in the specified directory\n",
    "json_file_paths = glob.glob(os.path.join(json_directory, '*.json'))\n",
    "\n",
    "# List to hold DataFrames\n",
    "data = pd.DataFrame()\n",
    "\n",
    "# Loop through each file path\n",
    "for path in json_file_paths:\n",
    "    with open(path, 'r') as file:\n",
    "        jsonfile = json.load(file)\n",
    "    # Normalize the nested JSON data and append to the list\n",
    "    newdata = pd.json_normalize(jsonfile['data']['results'])\n",
    "    data = pd.concat([data, newdata], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>last_update_date</th>\n",
       "      <th>tags</th>\n",
       "      <th>permalink</th>\n",
       "      <th>status</th>\n",
       "      <th>list_date</th>\n",
       "      <th>open_houses</th>\n",
       "      <th>branding</th>\n",
       "      <th>list_price</th>\n",
       "      <th>property_id</th>\n",
       "      <th>photos</th>\n",
       "      <th>...</th>\n",
       "      <th>location.county.fips_code</th>\n",
       "      <th>location.county.name</th>\n",
       "      <th>primary_photo</th>\n",
       "      <th>source</th>\n",
       "      <th>products</th>\n",
       "      <th>location.address.coordinate</th>\n",
       "      <th>other_listings</th>\n",
       "      <th>community.advertisers</th>\n",
       "      <th>community.description.name</th>\n",
       "      <th>location.county</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-09-19T20:52:50Z</td>\n",
       "      <td>[carport, community_outdoor_space, cul_de_sac,...</td>\n",
       "      <td>9453-Herbert-Pl_Juneau_AK_99801_M90744-30767</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-06-29T21:16:25.000000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'name': 'EXP Realty LLC - Southeast Alaska',...</td>\n",
       "      <td>554950.0</td>\n",
       "      <td>9074430767</td>\n",
       "      <td>[{'tags': [{'label': 'house_view', 'probabilit...</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>Juneau</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>8477-Thunder-Mountain-Rd_Juneau_AK_99801_M9424...</td>\n",
       "      <td>sold</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'name': None, 'photo': None, 'type': 'Office'}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9424983842</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>Juneau</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4515-Glacier-Hwy_Juneau_AK_99801_M94790-68516</td>\n",
       "      <td>sold</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'name': None, 'photo': None, 'type': 'Office'}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9479068516</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>Juneau</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>17850-Point-Stephens-Rd_Juneau_AK_99801_M98793...</td>\n",
       "      <td>sold</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'name': None, 'photo': None, 'type': 'Office'}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9879331943</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>Juneau</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>9951-Stephen-Richards-Memorial-Dr_Juneau_AK_99...</td>\n",
       "      <td>sold</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'name': None, 'photo': None, 'type': 'Office'}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9521639574</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>Juneau</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       last_update_date                                               tags  \\\n",
       "0  2023-09-19T20:52:50Z  [carport, community_outdoor_space, cul_de_sac,...   \n",
       "1                  None                                               None   \n",
       "2                  None                                               None   \n",
       "3                  None                                               None   \n",
       "4                  None                                               None   \n",
       "\n",
       "                                           permalink status  \\\n",
       "0       9453-Herbert-Pl_Juneau_AK_99801_M90744-30767   sold   \n",
       "1  8477-Thunder-Mountain-Rd_Juneau_AK_99801_M9424...   sold   \n",
       "2      4515-Glacier-Hwy_Juneau_AK_99801_M94790-68516   sold   \n",
       "3  17850-Point-Stephens-Rd_Juneau_AK_99801_M98793...   sold   \n",
       "4  9951-Stephen-Richards-Memorial-Dr_Juneau_AK_99...   sold   \n",
       "\n",
       "                     list_date open_houses  \\\n",
       "0  2023-06-29T21:16:25.000000Z        None   \n",
       "1                         None        None   \n",
       "2                         None        None   \n",
       "3                         None        None   \n",
       "4                         None        None   \n",
       "\n",
       "                                            branding  list_price property_id  \\\n",
       "0  [{'name': 'EXP Realty LLC - Southeast Alaska',...    554950.0  9074430767   \n",
       "1  [{'name': None, 'photo': None, 'type': 'Office'}]         NaN  9424983842   \n",
       "2  [{'name': None, 'photo': None, 'type': 'Office'}]         NaN  9479068516   \n",
       "3  [{'name': None, 'photo': None, 'type': 'Office'}]         NaN  9879331943   \n",
       "4  [{'name': None, 'photo': None, 'type': 'Office'}]         NaN  9521639574   \n",
       "\n",
       "                                              photos  ...  \\\n",
       "0  [{'tags': [{'label': 'house_view', 'probabilit...  ...   \n",
       "1                                               None  ...   \n",
       "2                                               None  ...   \n",
       "3                                               None  ...   \n",
       "4                                               None  ...   \n",
       "\n",
       "  location.county.fips_code location.county.name primary_photo  source  \\\n",
       "0                      None               Juneau           NaN     NaN   \n",
       "1                      None               Juneau           NaN     NaN   \n",
       "2                      None               Juneau           NaN     NaN   \n",
       "3                      None               Juneau           NaN     NaN   \n",
       "4                      None               Juneau           NaN     NaN   \n",
       "\n",
       "  products location.address.coordinate other_listings community.advertisers  \\\n",
       "0      NaN                         NaN            NaN                   NaN   \n",
       "1      NaN                         NaN            NaN                   NaN   \n",
       "2      NaN                         NaN            NaN                   NaN   \n",
       "3      NaN                         NaN            NaN                   NaN   \n",
       "4      NaN                         NaN            NaN                   NaN   \n",
       "\n",
       "  community.description.name location.county  \n",
       "0                        NaN             NaN  \n",
       "1                        NaN             NaN  \n",
       "2                        NaN             NaN  \n",
       "3                        NaN             NaN  \n",
       "4                        NaN             NaN  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "last_update_date                 66\n",
       "tags                            553\n",
       "permalink                        32\n",
       "status                           32\n",
       "list_date                       439\n",
       "                               ... \n",
       "location.address.coordinate    8191\n",
       "other_listings                 8191\n",
       "community.advertisers          8186\n",
       "community.description.name     8186\n",
       "location.county                8191\n",
       "Length: 67, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data Cleaning \n",
    "\n",
    "#Count the number of missing values in each column\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop columns with more than 50% missing values\n",
    "data = data.dropna(thresh=0.5*len(data), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['last_update_date', 'tags', 'permalink', 'status', 'list_date',\n",
       "       'branding', 'list_price', 'property_id', 'photos', 'listing_id',\n",
       "       'matterport', 'primary_photo.href', 'source.agents', 'source.type',\n",
       "       'description.year_built', 'description.sold_date',\n",
       "       'description.sold_price', 'description.baths_full',\n",
       "       'description.lot_sqft', 'description.sqft', 'description.baths',\n",
       "       'description.garage', 'description.stories', 'description.beds',\n",
       "       'description.type', 'lead_attributes.show_contact_an_agent',\n",
       "       'flags.is_new_listing', 'products.brand_name', 'other_listings.rdc',\n",
       "       'location.address.postal_code', 'location.address.state',\n",
       "       'location.address.coordinate.lon', 'location.address.coordinate.lat',\n",
       "       'location.address.city', 'location.address.state_code',\n",
       "       'location.address.line', 'location.street_view_url',\n",
       "       'location.county.fips_code', 'location.county.name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting relevant columns\n",
    "\n",
    "rel_columns = ['description.year_built', 'tags', 'permalink', 'status', 'list_price', 'property_id', 'listing_id', 'primary_photo.href',\n",
    "                'description.sold_date', 'description.sold_price','description.lot_sqft', 'description.sqft', 'description.baths',\n",
    "                'description.garage','description.beds','location.address.postal_code', 'location.address.state','location.address.city']\n",
    "\n",
    "data_rel = data[rel_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_names = ['year_built', 'tags', 'permalink', 'status', 'list_price', 'property_id', 'listing', 'primary_photo',\n",
    "                'sold_date', 'sold_price','lot_sqft', 'sqft', 'baths', 'garages', 'beds','postal_code', 'state','city']\n",
    "\n",
    "data_rel.columns = new_names        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_built</th>\n",
       "      <th>tags</th>\n",
       "      <th>permalink</th>\n",
       "      <th>status</th>\n",
       "      <th>list_price</th>\n",
       "      <th>property_id</th>\n",
       "      <th>listing</th>\n",
       "      <th>primary_photo</th>\n",
       "      <th>sold_date</th>\n",
       "      <th>sold_price</th>\n",
       "      <th>lot_sqft</th>\n",
       "      <th>sqft</th>\n",
       "      <th>baths</th>\n",
       "      <th>garages</th>\n",
       "      <th>beds</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1963.0</td>\n",
       "      <td>[carport, community_outdoor_space, cul_de_sac,...</td>\n",
       "      <td>9453-Herbert-Pl_Juneau_AK_99801_M90744-30767</td>\n",
       "      <td>sold</td>\n",
       "      <td>554950.0</td>\n",
       "      <td>9074430767</td>\n",
       "      <td>2957241843</td>\n",
       "      <td>https://ap.rdcpix.com/07097d34c98a59ebb7996889...</td>\n",
       "      <td>2023-09-18</td>\n",
       "      <td>None</td>\n",
       "      <td>10454.0</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>99801</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>Juneau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>8477-Thunder-Mountain-Rd_Juneau_AK_99801_M9424...</td>\n",
       "      <td>sold</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9424983842</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-22</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99801</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>Juneau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>4515-Glacier-Hwy_Juneau_AK_99801_M94790-68516</td>\n",
       "      <td>sold</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9479068516</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-22</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99801</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>Juneau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>17850-Point-Stephens-Rd_Juneau_AK_99801_M98793...</td>\n",
       "      <td>sold</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9879331943</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-21</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99801</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>Juneau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>9951-Stephen-Richards-Memorial-Dr_Juneau_AK_99...</td>\n",
       "      <td>sold</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9521639574</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-21</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99801</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>Juneau</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year_built                                               tags  \\\n",
       "0      1963.0  [carport, community_outdoor_space, cul_de_sac,...   \n",
       "1         NaN                                               None   \n",
       "2         NaN                                               None   \n",
       "3         NaN                                               None   \n",
       "4         NaN                                               None   \n",
       "\n",
       "                                           permalink status  list_price  \\\n",
       "0       9453-Herbert-Pl_Juneau_AK_99801_M90744-30767   sold    554950.0   \n",
       "1  8477-Thunder-Mountain-Rd_Juneau_AK_99801_M9424...   sold         NaN   \n",
       "2      4515-Glacier-Hwy_Juneau_AK_99801_M94790-68516   sold         NaN   \n",
       "3  17850-Point-Stephens-Rd_Juneau_AK_99801_M98793...   sold         NaN   \n",
       "4  9951-Stephen-Richards-Memorial-Dr_Juneau_AK_99...   sold         NaN   \n",
       "\n",
       "  property_id     listing                                      primary_photo  \\\n",
       "0  9074430767  2957241843  https://ap.rdcpix.com/07097d34c98a59ebb7996889...   \n",
       "1  9424983842        None                                                NaN   \n",
       "2  9479068516        None                                                NaN   \n",
       "3  9879331943        None                                                NaN   \n",
       "4  9521639574        None                                                NaN   \n",
       "\n",
       "    sold_date sold_price  lot_sqft    sqft  baths  garages  beds postal_code  \\\n",
       "0  2023-09-18       None   10454.0  1821.0    2.0      1.0   3.0       99801   \n",
       "1  2023-08-22       None       NaN     NaN    NaN      NaN   NaN       99801   \n",
       "2  2023-08-22       None       NaN     NaN    NaN      NaN   NaN       99801   \n",
       "3  2023-08-21       None       NaN     NaN    NaN      NaN   NaN       99801   \n",
       "4  2023-08-21       None       NaN     NaN    NaN      NaN   NaN       99801   \n",
       "\n",
       "    state    city  \n",
       "0  Alaska  Juneau  \n",
       "1  Alaska  Juneau  \n",
       "2  Alaska  Juneau  \n",
       "3  Alaska  Juneau  \n",
       "4  Alaska  Juneau  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_rel.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rel.to_csv('../data/dataframes/raw_merged_df_data.csv') #Save the data to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year_built       float64\n",
       "tags              object\n",
       "permalink         object\n",
       "status            object\n",
       "list_price       float64\n",
       "property_id       object\n",
       "listing           object\n",
       "primary_photo     object\n",
       "sold_date         object\n",
       "sold_price        object\n",
       "lot_sqft         float64\n",
       "sqft             float64\n",
       "baths            float64\n",
       "garages          float64\n",
       "beds             float64\n",
       "postal_code       object\n",
       "state             object\n",
       "city              object\n",
       "dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_rel.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\410462368.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_rel['sold_price'] = pd.to_numeric(data_rel['sold_price'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "#Removing nulls \n",
    "data_rel['sold_price'] = pd.to_numeric(data_rel['sold_price'], errors='coerce')\n",
    "dataframe = data_rel[(data_rel['sold_price'] > 0) &\n",
    "                     (data_rel['list_price'] > 0) &\n",
    "                     (data_rel['baths'] > 0) &\n",
    "                     (data_rel['lot_sqft'] > 0) &\n",
    "                     (data_rel['sqft'] > 0) &\n",
    "                     (data_rel['year_built'] > 0) &\n",
    "                     (data_rel['beds'] > 0)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\664892495.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data_rel['garages'].fillna(0, inplace=True)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\664892495.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_rel['garages'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "data_rel['garages'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\2983386690.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_rel.dropna(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "data_rel.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1597255075.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_rel['year_built'] = data_rel['year_built'].astype(int)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1597255075.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_rel['beds'] = data_rel['beds'].astype(int)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1597255075.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_rel['baths'] = data_rel['baths'].astype(int)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1597255075.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_rel['garages'] = data_rel['garages'].astype(int)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1597255075.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_rel['lot_sqft'] = data_rel['lot_sqft'].astype(int)\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\1597255075.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_rel['sqft'] = data_rel['sqft'].astype(int)\n"
     ]
    }
   ],
   "source": [
    "#Convert float to int for year_built, beds, baths, garages, lot_sqft, sqft\n",
    "data_rel['year_built'] = data_rel['year_built'].astype(int)\n",
    "data_rel['beds'] = data_rel['beds'].astype(int)\n",
    "data_rel['baths'] = data_rel['baths'].astype(int)\n",
    "data_rel['garages'] = data_rel['garages'].astype(int)\n",
    "data_rel['lot_sqft'] = data_rel['lot_sqft'].astype(int)\n",
    "data_rel['sqft'] = data_rel['sqft'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n"
     ]
    }
   ],
   "source": [
    "#Encode tags\n",
    "#Testing the function \n",
    "testing  = data_rel.head(25)\n",
    "testing_tags = encode_tags(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[tag] = 0\n",
      "c:\\Users\\Mahika and Rutva\\Desktop\\Midterm LHL\\Data-Project-Supervised-Learning\\notebooks\\functions_variables.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[tag] = 0\n"
     ]
    }
   ],
   "source": [
    "#Applying the function to the entire dataset\n",
    "data_rel = encode_tags(data_rel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count the number of unique tags using the new columns\n",
    "just_tags = data_rel.iloc[:, 18:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count the number of values in each unique tag\n",
    "counts_tags = just_tags.sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "garage_1_or_more               3290\n",
       "central_air                    2911\n",
       "community_outdoor_space        2721\n",
       "basement                       2535\n",
       "dishwasher                     2517\n",
       "fireplace                      2497\n",
       "forced_air                     2335\n",
       "garage_2_or_more               2263\n",
       "two_or_more_stories            2251\n",
       "single_story                   2215\n",
       "hardwood_floors                1877\n",
       "washer_dryer                   1565\n",
       "laundry_room                   1504\n",
       "shopping                       1339\n",
       "dining_room                    1125\n",
       "community_security_features    1122\n",
       "recreation_facilities          1103\n",
       "view                            988\n",
       "central_heat                    968\n",
       "family_room                     945\n",
       "dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#See the top 20 tags\n",
    "counts_tags.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['view', 'central_heat', 'family_room', 'fenced_yard', 'city_view', 'floor_plan', 'new_roof', 'updated_kitchen', 'big_lot', 'farm', 'ensuite', 'rental_property', 'big_yard', 'ranch', 'corner_lot', 'energy_efficient', 'community_swimming_pool', 'modern_kitchen', 'open_floor_plan', 'garage_3_or_more', 'park', 'carport', 'high_ceiling', 'front_porch', 'groundscare', 'swimming_pool', 'trails', 'master_bedroom', 'views', 'vaulted_ceiling', 'disability_features', 'fixer_upper', 'cul_de_sac', 'hill_or_mountain_view', 'large_kitchen', 'den_or_office', 'lake', 'water_view', 'investment_opportunity', 'efficient', 'granite_kitchen', 'golf_course', 'medicalcare', 'private_backyard', 'community_clubhouse', 'master_suite', 'tennis_court', 'rv_or_boat_parking', 'clubhouse', 'maintenance', 'playground', 'open_kitchen', 'pets_allowed', 'tennis', 'no_hoa', 'community_tennis_court', 'waterfront', 'spa_or_hot_tub', 'lake_view', 'pond', 'community_golf', 'library', 'community_park', 'gated_community', 'cathedral_ceiling', 'solar_system', 'security', 'big_bathroom', 'community_gym', 'gourmet_kitchen', 'hoa', 'rv_parking', 'community_spa_or_hot_tub', 'fruit_trees', 'marina', 'open_house', 'smart_homes', 'mountain_view', 'storm_shelter', 'river_view', 'jack_and_jill_bathroom', 'community_center', 'private_bathroom', 'senior_community', 'solar_panels', 'master_bathroom', 'golf_course_lot_or_frontage', 'beautiful_backyard', 'game_room', 'large_porch', 'furniture', 'beach', 'golf_course_view', 'coffer_ceiling', 'wooded_land', 'community_boat_facilities', 'elevator', 'kitchen_island', 'exposed_brick', 'outbuilding', 'outdoor_kitchen', 'media_room', 'wrap_around_porch', 'basketball', 'basketball_court', 'screen_porch', 'ocean_view', 'horse_facilities', 'greenbelt', 'volleyball', 'handicap_access', 'well_water', 'soccer', 'private_courtyard', 'guest_house', 'river_access', 'guest_parking', 'wine_cellar', 'theater_room', 'baseball', 'first_floor_master_bedroom', 'white_kitchen', 'two_kitchen', 'two_master_suites', 'greenhouse', 'boat_dock', 'private_parking', 'fenced_courtyard', 'courtyard_entry', 'detached_guest_house', 'community_horse_facilities', 'low_hoa'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[88], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Drop the columns with less than 1000 values (approx half of the data)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m data_rel \u001b[38;5;241m=\u001b[39m \u001b[43mdata_rel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcounts_tags\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcounts_tags\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Mahika and Rutva\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5434\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5435\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5443\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5444\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5445\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5446\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5579\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5583\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5587\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5588\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5589\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Mahika and Rutva\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4786\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4788\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mc:\\Users\\Mahika and Rutva\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:4830\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4828\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4830\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4831\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4833\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Mahika and Rutva\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['view', 'central_heat', 'family_room', 'fenced_yard', 'city_view', 'floor_plan', 'new_roof', 'updated_kitchen', 'big_lot', 'farm', 'ensuite', 'rental_property', 'big_yard', 'ranch', 'corner_lot', 'energy_efficient', 'community_swimming_pool', 'modern_kitchen', 'open_floor_plan', 'garage_3_or_more', 'park', 'carport', 'high_ceiling', 'front_porch', 'groundscare', 'swimming_pool', 'trails', 'master_bedroom', 'views', 'vaulted_ceiling', 'disability_features', 'fixer_upper', 'cul_de_sac', 'hill_or_mountain_view', 'large_kitchen', 'den_or_office', 'lake', 'water_view', 'investment_opportunity', 'efficient', 'granite_kitchen', 'golf_course', 'medicalcare', 'private_backyard', 'community_clubhouse', 'master_suite', 'tennis_court', 'rv_or_boat_parking', 'clubhouse', 'maintenance', 'playground', 'open_kitchen', 'pets_allowed', 'tennis', 'no_hoa', 'community_tennis_court', 'waterfront', 'spa_or_hot_tub', 'lake_view', 'pond', 'community_golf', 'library', 'community_park', 'gated_community', 'cathedral_ceiling', 'solar_system', 'security', 'big_bathroom', 'community_gym', 'gourmet_kitchen', 'hoa', 'rv_parking', 'community_spa_or_hot_tub', 'fruit_trees', 'marina', 'open_house', 'smart_homes', 'mountain_view', 'storm_shelter', 'river_view', 'jack_and_jill_bathroom', 'community_center', 'private_bathroom', 'senior_community', 'solar_panels', 'master_bathroom', 'golf_course_lot_or_frontage', 'beautiful_backyard', 'game_room', 'large_porch', 'furniture', 'beach', 'golf_course_view', 'coffer_ceiling', 'wooded_land', 'community_boat_facilities', 'elevator', 'kitchen_island', 'exposed_brick', 'outbuilding', 'outdoor_kitchen', 'media_room', 'wrap_around_porch', 'basketball', 'basketball_court', 'screen_porch', 'ocean_view', 'horse_facilities', 'greenbelt', 'volleyball', 'handicap_access', 'well_water', 'soccer', 'private_courtyard', 'guest_house', 'river_access', 'guest_parking', 'wine_cellar', 'theater_room', 'baseball', 'first_floor_master_bedroom', 'white_kitchen', 'two_kitchen', 'two_master_suites', 'greenhouse', 'boat_dock', 'private_parking', 'fenced_courtyard', 'courtyard_entry', 'detached_guest_house', 'community_horse_facilities', 'low_hoa'] not found in axis\""
     ]
    }
   ],
   "source": [
    "#Drop the columns with less than 1000 values (approx half of the data)\n",
    "#data_rel = data_rel.drop(columns=counts_tags[counts_tags < 1000].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop shopping and washer_dryer\n",
    "#data_rel = data_rel.drop(columns=['shopping', 'washer_dryer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\3816531660.py:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '31      1\n",
      "33      0\n",
      "34      0\n",
      "35      0\n",
      "36      0\n",
      "       ..\n",
      "8156    0\n",
      "8164    0\n",
      "8165    0\n",
      "8181    1\n",
      "8185    1\n",
      "Name: garage_1_or_more, Length: 5007, dtype: category\n",
      "Categories (2, int64): [0, 1]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data_rel.iloc[:, 18:] = data_rel.iloc[:, 18:].astype('category')\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\3816531660.py:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '31      0\n",
      "33      0\n",
      "34      0\n",
      "35      0\n",
      "36      0\n",
      "       ..\n",
      "8156    1\n",
      "8164    0\n",
      "8165    1\n",
      "8181    1\n",
      "8185    0\n",
      "Name: forced_air, Length: 5007, dtype: category\n",
      "Categories (2, int64): [0, 1]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data_rel.iloc[:, 18:] = data_rel.iloc[:, 18:].astype('category')\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\3816531660.py:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '31      0\n",
      "33      1\n",
      "34      0\n",
      "35      0\n",
      "36      0\n",
      "       ..\n",
      "8156    0\n",
      "8164    0\n",
      "8165    0\n",
      "8181    0\n",
      "8185    0\n",
      "Name: recreation_facilities, Length: 5007, dtype: category\n",
      "Categories (2, int64): [0, 1]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data_rel.iloc[:, 18:] = data_rel.iloc[:, 18:].astype('category')\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\3816531660.py:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '31      0\n",
      "33      1\n",
      "34      1\n",
      "35      1\n",
      "36      1\n",
      "       ..\n",
      "8156    1\n",
      "8164    0\n",
      "8165    0\n",
      "8181    0\n",
      "8185    1\n",
      "Name: single_story, Length: 5007, dtype: category\n",
      "Categories (2, int64): [0, 1]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data_rel.iloc[:, 18:] = data_rel.iloc[:, 18:].astype('category')\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\3816531660.py:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '31      1\n",
      "33      0\n",
      "34      0\n",
      "35      0\n",
      "36      0\n",
      "       ..\n",
      "8156    0\n",
      "8164    0\n",
      "8165    1\n",
      "8181    1\n",
      "8185    0\n",
      "Name: two_or_more_stories, Length: 5007, dtype: category\n",
      "Categories (2, int64): [0, 1]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data_rel.iloc[:, 18:] = data_rel.iloc[:, 18:].astype('category')\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\3816531660.py:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '31      0\n",
      "33      0\n",
      "34      0\n",
      "35      1\n",
      "36      1\n",
      "       ..\n",
      "8156    0\n",
      "8164    0\n",
      "8165    0\n",
      "8181    0\n",
      "8185    0\n",
      "Name: dishwasher, Length: 5007, dtype: category\n",
      "Categories (2, int64): [0, 1]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data_rel.iloc[:, 18:] = data_rel.iloc[:, 18:].astype('category')\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\3816531660.py:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '31      0\n",
      "33      0\n",
      "34      0\n",
      "35      1\n",
      "36      0\n",
      "       ..\n",
      "8156    0\n",
      "8164    0\n",
      "8165    0\n",
      "8181    0\n",
      "8185    0\n",
      "Name: community_security_features, Length: 5007, dtype: category\n",
      "Categories (2, int64): [0, 1]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data_rel.iloc[:, 18:] = data_rel.iloc[:, 18:].astype('category')\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\3816531660.py:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '31      0\n",
      "33      0\n",
      "34      0\n",
      "35      0\n",
      "36      0\n",
      "       ..\n",
      "8156    0\n",
      "8164    0\n",
      "8165    1\n",
      "8181    1\n",
      "8185    1\n",
      "Name: basement, Length: 5007, dtype: category\n",
      "Categories (2, int64): [0, 1]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data_rel.iloc[:, 18:] = data_rel.iloc[:, 18:].astype('category')\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\3816531660.py:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '31      0\n",
      "33      0\n",
      "34      0\n",
      "35      1\n",
      "36      1\n",
      "       ..\n",
      "8156    0\n",
      "8164    0\n",
      "8165    1\n",
      "8181    0\n",
      "8185    0\n",
      "Name: fireplace, Length: 5007, dtype: category\n",
      "Categories (2, int64): [0, 1]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data_rel.iloc[:, 18:] = data_rel.iloc[:, 18:].astype('category')\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\3816531660.py:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '31      0\n",
      "33      1\n",
      "34      0\n",
      "35      1\n",
      "36      1\n",
      "       ..\n",
      "8156    1\n",
      "8164    0\n",
      "8165    1\n",
      "8181    1\n",
      "8185    1\n",
      "Name: central_air, Length: 5007, dtype: category\n",
      "Categories (2, int64): [0, 1]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data_rel.iloc[:, 18:] = data_rel.iloc[:, 18:].astype('category')\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\3816531660.py:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '31      0\n",
      "33      0\n",
      "34      0\n",
      "35      0\n",
      "36      0\n",
      "       ..\n",
      "8156    0\n",
      "8164    0\n",
      "8165    0\n",
      "8181    0\n",
      "8185    0\n",
      "Name: garage_2_or_more, Length: 5007, dtype: category\n",
      "Categories (2, int64): [0, 1]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data_rel.iloc[:, 18:] = data_rel.iloc[:, 18:].astype('category')\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\3816531660.py:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '31      0\n",
      "33      0\n",
      "34      0\n",
      "35      1\n",
      "36      1\n",
      "       ..\n",
      "8156    0\n",
      "8164    0\n",
      "8165    0\n",
      "8181    0\n",
      "8185    0\n",
      "Name: laundry_room, Length: 5007, dtype: category\n",
      "Categories (2, int64): [0, 1]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data_rel.iloc[:, 18:] = data_rel.iloc[:, 18:].astype('category')\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\3816531660.py:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '31      1\n",
      "33      0\n",
      "34      0\n",
      "35      0\n",
      "36      1\n",
      "       ..\n",
      "8156    0\n",
      "8164    0\n",
      "8165    1\n",
      "8181    0\n",
      "8185    0\n",
      "Name: hardwood_floors, Length: 5007, dtype: category\n",
      "Categories (2, int64): [0, 1]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data_rel.iloc[:, 18:] = data_rel.iloc[:, 18:].astype('category')\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\3816531660.py:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '31      0\n",
      "33      1\n",
      "34      0\n",
      "35      1\n",
      "36      1\n",
      "       ..\n",
      "8156    0\n",
      "8164    0\n",
      "8165    0\n",
      "8181    0\n",
      "8185    0\n",
      "Name: community_outdoor_space, Length: 5007, dtype: category\n",
      "Categories (2, int64): [0, 1]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data_rel.iloc[:, 18:] = data_rel.iloc[:, 18:].astype('category')\n",
      "C:\\Users\\Mahika and Rutva\\AppData\\Local\\Temp\\ipykernel_24616\\3816531660.py:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '31      0\n",
      "33      0\n",
      "34      0\n",
      "35      0\n",
      "36      0\n",
      "       ..\n",
      "8156    0\n",
      "8164    0\n",
      "8165    0\n",
      "8181    0\n",
      "8185    0\n",
      "Name: dining_room, Length: 5007, dtype: category\n",
      "Categories (2, int64): [0, 1]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data_rel.iloc[:, 18:] = data_rel.iloc[:, 18:].astype('category')\n"
     ]
    }
   ],
   "source": [
    "#Change the tag columns to categorical\n",
    "data_rel.iloc[:, 18:] = data_rel.iloc[:, 18:].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_built</th>\n",
       "      <th>list_price</th>\n",
       "      <th>sold_price</th>\n",
       "      <th>lot_sqft</th>\n",
       "      <th>sqft</th>\n",
       "      <th>baths</th>\n",
       "      <th>garages</th>\n",
       "      <th>beds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5007.000000</td>\n",
       "      <td>5.007000e+03</td>\n",
       "      <td>5.007000e+03</td>\n",
       "      <td>5.007000e+03</td>\n",
       "      <td>5007.000000</td>\n",
       "      <td>5007.000000</td>\n",
       "      <td>5007.000000</td>\n",
       "      <td>5007.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1966.404434</td>\n",
       "      <td>4.327309e+05</td>\n",
       "      <td>4.251500e+05</td>\n",
       "      <td>1.562188e+05</td>\n",
       "      <td>1934.589375</td>\n",
       "      <td>2.334332</td>\n",
       "      <td>1.191732</td>\n",
       "      <td>3.336129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>34.675178</td>\n",
       "      <td>5.749692e+05</td>\n",
       "      <td>5.584667e+05</td>\n",
       "      <td>4.392940e+06</td>\n",
       "      <td>1043.020121</td>\n",
       "      <td>1.038831</td>\n",
       "      <td>1.204925</td>\n",
       "      <td>1.251551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1836.000000</td>\n",
       "      <td>1.990000e+04</td>\n",
       "      <td>9.000000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1947.000000</td>\n",
       "      <td>2.250000e+05</td>\n",
       "      <td>2.215000e+05</td>\n",
       "      <td>4.792000e+03</td>\n",
       "      <td>1288.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1970.000000</td>\n",
       "      <td>3.300000e+05</td>\n",
       "      <td>3.300000e+05</td>\n",
       "      <td>7.675000e+03</td>\n",
       "      <td>1680.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1995.000000</td>\n",
       "      <td>4.949000e+05</td>\n",
       "      <td>4.850000e+05</td>\n",
       "      <td>1.176100e+04</td>\n",
       "      <td>2277.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2023.000000</td>\n",
       "      <td>1.250000e+07</td>\n",
       "      <td>1.250000e+07</td>\n",
       "      <td>1.390435e+08</td>\n",
       "      <td>11218.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        year_built    list_price    sold_price      lot_sqft          sqft  \\\n",
       "count  5007.000000  5.007000e+03  5.007000e+03  5.007000e+03   5007.000000   \n",
       "mean   1966.404434  4.327309e+05  4.251500e+05  1.562188e+05   1934.589375   \n",
       "std      34.675178  5.749692e+05  5.584667e+05  4.392940e+06   1043.020121   \n",
       "min    1836.000000  1.990000e+04  9.000000e+03  0.000000e+00    120.000000   \n",
       "25%    1947.000000  2.250000e+05  2.215000e+05  4.792000e+03   1288.000000   \n",
       "50%    1970.000000  3.300000e+05  3.300000e+05  7.675000e+03   1680.000000   \n",
       "75%    1995.000000  4.949000e+05  4.850000e+05  1.176100e+04   2277.000000   \n",
       "max    2023.000000  1.250000e+07  1.250000e+07  1.390435e+08  11218.000000   \n",
       "\n",
       "             baths      garages         beds  \n",
       "count  5007.000000  5007.000000  5007.000000  \n",
       "mean      2.334332     1.191732     3.336129  \n",
       "std       1.038831     1.204925     1.251551  \n",
       "min       0.000000     0.000000     0.000000  \n",
       "25%       2.000000     0.000000     3.000000  \n",
       "50%       2.000000     1.000000     3.000000  \n",
       "75%       3.000000     2.000000     4.000000  \n",
       "max       9.000000    11.000000    12.000000  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_rel.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>garage_1_or_more</th>\n",
       "      <th>forced_air</th>\n",
       "      <th>recreation_facilities</th>\n",
       "      <th>single_story</th>\n",
       "      <th>two_or_more_stories</th>\n",
       "      <th>dishwasher</th>\n",
       "      <th>community_security_features</th>\n",
       "      <th>basement</th>\n",
       "      <th>fireplace</th>\n",
       "      <th>central_air</th>\n",
       "      <th>garage_2_or_more</th>\n",
       "      <th>laundry_room</th>\n",
       "      <th>hardwood_floors</th>\n",
       "      <th>community_outdoor_space</th>\n",
       "      <th>dining_room</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1717</td>\n",
       "      <td>2672</td>\n",
       "      <td>3904</td>\n",
       "      <td>2792</td>\n",
       "      <td>2756</td>\n",
       "      <td>2490</td>\n",
       "      <td>3885</td>\n",
       "      <td>2472</td>\n",
       "      <td>2510</td>\n",
       "      <td>2096</td>\n",
       "      <td>2744</td>\n",
       "      <td>3503</td>\n",
       "      <td>3130</td>\n",
       "      <td>2286</td>\n",
       "      <td>3882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3290</td>\n",
       "      <td>2335</td>\n",
       "      <td>1103</td>\n",
       "      <td>2215</td>\n",
       "      <td>2251</td>\n",
       "      <td>2517</td>\n",
       "      <td>1122</td>\n",
       "      <td>2535</td>\n",
       "      <td>2497</td>\n",
       "      <td>2911</td>\n",
       "      <td>2263</td>\n",
       "      <td>1504</td>\n",
       "      <td>1877</td>\n",
       "      <td>2721</td>\n",
       "      <td>1125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   garage_1_or_more  forced_air  recreation_facilities  single_story  \\\n",
       "0              1717        2672                   3904          2792   \n",
       "1              3290        2335                   1103          2215   \n",
       "\n",
       "   two_or_more_stories  dishwasher  community_security_features  basement  \\\n",
       "0                 2756        2490                         3885      2472   \n",
       "1                 2251        2517                         1122      2535   \n",
       "\n",
       "   fireplace  central_air  garage_2_or_more  laundry_room  hardwood_floors  \\\n",
       "0       2510         2096              2744          3503             3130   \n",
       "1       2497         2911              2263          1504             1877   \n",
       "\n",
       "   community_outdoor_space  dining_room  \n",
       "0                     2286         3882  \n",
       "1                     2721         1125  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count the 1s and 0s in each tag column \n",
    "data_rel.iloc[:, 18:].apply(pd.Series.value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the clean data to csv file\n",
    "data_rel.to_csv('../data/dataframes/cleaned_data_eda.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory: ../data\n"
     ]
    }
   ],
   "source": [
    "# Relative path from notebooks to data\n",
    "data_dir = '../data'\n",
    "\n",
    "# Print the data directory to verify\n",
    "print(f\"Data directory: {data_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check if the directory exists\n",
    "# if not os.path.exists(data_dir):\n",
    "#     print(\"Data directory does not exist!\")\n",
    "# else:\n",
    "#     # List all JSON files in the data directory\n",
    "#     files = [f for f in os.listdir(data_dir) if f.endswith('.json')]\n",
    "\n",
    "#     # Initialize an empty list to store DataFrames\n",
    "#     dfs = []\n",
    "\n",
    "#     # Read and process each JSON file into a DataFrame and append to the list\n",
    "#     for file in files:\n",
    "#         file_path = os.path.join(data_dir, file)\n",
    "        \n",
    "#         # Read the JSON file into a DataFrame\n",
    "#         df = pd.read_json(file_path)\n",
    "        \n",
    "#         # Split the filename into parts (assuming parts are separated by underscores)\n",
    "#         filename_parts = os.path.splitext(file)[0].split('_')\n",
    "        \n",
    "#         # Ensure there are exactly three parts (add empty strings if necessary)\n",
    "#         while len(filename_parts) < 3:\n",
    "#             filename_parts.append('')\n",
    "        \n",
    "#         # Add filename parts as new columns to the DataFrame\n",
    "#         df['part1'] = filename_parts[0]\n",
    "#         df['part2'] = filename_parts[1]\n",
    "#         df['part3'] = filename_parts[2]\n",
    "        \n",
    "#         # Append the DataFrame to the list\n",
    "#         dfs.append(df)\n",
    "\n",
    "#     # Concatenate all DataFrames into a single DataFrame\n",
    "#     combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Juneau', 'Montgomery', 'LittleRock', 'Phoenix', 'Sacramento',\n",
       "       'Denver', 'Hartford', 'Dover', 'Tallahassee', 'Atlanta',\n",
       "       'Honolulu', 'DesMoines', 'Boise', 'Springfield', 'Indianapolis',\n",
       "       'Topeka', 'Frankfort', 'BatonRouge', 'Boston', 'Annapolis',\n",
       "       'Augusta', 'Lansing', 'St.Paul', 'JeffersonCity', 'Jackson',\n",
       "       'Helena', 'Raleigh', 'Bismarck', 'Lincoln', 'Concord', 'Trenton',\n",
       "       'SantaFe', 'CarsonCity', 'Albany', 'Columbus', 'OklahomaCity',\n",
       "       'Salem', 'Harrisburg', 'Providence', 'Columbia', 'Pierre',\n",
       "       'Nashville', 'Austin', 'SaltLakeCity', 'Richmond', 'Montpelier',\n",
       "       'Olympia', 'Madison', 'Charleston', 'Cheyenne'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combined_df['part2'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data from one file \n",
    "file_path_dummy = os.path.join(data_dir, 'AZ_Phoenix_0.json')\n",
    "df_dummy = pd.read_json(file_path_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>200</td>\n",
       "      <td>5100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>results</th>\n",
       "      <td>200</td>\n",
       "      <td>[{'primary_photo': {'href': 'https://ap.rdcpix...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         status                                               data\n",
       "total       200                                               5100\n",
       "count       200                                                 42\n",
       "results     200  [{'primary_photo': {'href': 'https://ap.rdcpix..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, ensure that you have all sales in a dataframe.\n",
    "- Is each cell one value, or do some cells have lists?\n",
    "- Maybe the \"tags\" will help create some features.\n",
    "- What are the data types of each column?\n",
    "- Some sales may not actually include the sale price.  These rows should be dropped.\n",
    "- Some sales don't include the property type.\n",
    "- There are a lot of None values.  Should these be dropped or replaced with something?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and concatenate data here\n",
    "# drop or replace values as \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from one file\n",
    "with open(file_path_dummy, 'r') as file:\n",
    "    data = json.load(file)\n",
    "    results = data['data']['results']\n",
    "\n",
    "extracted_info = [extract_info(result) for result in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>permalink</th>\n",
       "      <th>status</th>\n",
       "      <th>list_date</th>\n",
       "      <th>sold_date</th>\n",
       "      <th>list_price</th>\n",
       "      <th>sold_price</th>\n",
       "      <th>year_built</th>\n",
       "      <th>beds</th>\n",
       "      <th>baths</th>\n",
       "      <th>sqft</th>\n",
       "      <th>lot_sqft</th>\n",
       "      <th>garage</th>\n",
       "      <th>tags</th>\n",
       "      <th>office_name</th>\n",
       "      <th>source_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8815-W-Pioneer-St_Tolleson_AZ_85353_M17818-19456</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-12-08T15:08:46.000000Z</td>\n",
       "      <td>2024-01-12</td>\n",
       "      <td>449000</td>\n",
       "      <td>445000</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2147.0</td>\n",
       "      <td>5663.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[central_air, community_outdoor_space, dishwas...</td>\n",
       "      <td>None</td>\n",
       "      <td>mls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2938-N-18th-Pl_Phoenix_AZ_85016_M24990-60512</td>\n",
       "      <td>sold</td>\n",
       "      <td>2022-02-01T05:25:28.000000Z</td>\n",
       "      <td>2024-01-10</td>\n",
       "      <td>385000</td>\n",
       "      <td>410000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6843.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[cul_de_sac, medicalcare]</td>\n",
       "      <td>None</td>\n",
       "      <td>mls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40320-N-Hickok-Ct_Phoenix_AZ_85086_M13341-66678</td>\n",
       "      <td>sold</td>\n",
       "      <td>2022-06-19T16:36:42.000000Z</td>\n",
       "      <td>2024-01-08</td>\n",
       "      <td>1298000</td>\n",
       "      <td>1206000</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4408.0</td>\n",
       "      <td>12197.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[community_clubhouse, community_outdoor_space,...</td>\n",
       "      <td>My Home Group Real Estate</td>\n",
       "      <td>mls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14612-S-1st-St-32_Phoenix_AZ_85048_M22978-80396</td>\n",
       "      <td>sold</td>\n",
       "      <td>2017-11-20T03:24:16.000000Z</td>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>375000</td>\n",
       "      <td>330000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28314.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[community_security_features, cul_de_sac, hill...</td>\n",
       "      <td>Keller Williams Realty Sonoran Living</td>\n",
       "      <td>mls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2323-W-Port-Au-Prince-Ln_Phoenix_AZ_85023_M219...</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-08-05T22:25:01.000000Z</td>\n",
       "      <td>2023-12-28</td>\n",
       "      <td>429900</td>\n",
       "      <td>415000</td>\n",
       "      <td>1973.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>9344.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[carport, community_outdoor_space, community_s...</td>\n",
       "      <td>Cooper Premier Properties LLC</td>\n",
       "      <td>mls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2625-E-Indian-School-Rd-Unit-127_Phoenix_AZ_85...</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-04-24T22:25:30.000000Z</td>\n",
       "      <td>2023-12-27</td>\n",
       "      <td>214900</td>\n",
       "      <td>200000</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>655.0</td>\n",
       "      <td>677.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[carport, community_clubhouse, community_outdo...</td>\n",
       "      <td>Nouveau Real Estate</td>\n",
       "      <td>mls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2316-E-Roosevelt-St_Phoenix_AZ_85006_M13012-14169</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-09-04T13:24:48.000000Z</td>\n",
       "      <td>2023-12-26</td>\n",
       "      <td>2200000</td>\n",
       "      <td>1900000</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46035.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[big_lot, new_roof]</td>\n",
       "      <td>None</td>\n",
       "      <td>mls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11814-N-31st-Dr_Phoenix_AZ_85029_M15208-82532</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-10-30T21:24:41.000000Z</td>\n",
       "      <td>2023-12-26</td>\n",
       "      <td>359900</td>\n",
       "      <td>359900</td>\n",
       "      <td>1967.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1576.0</td>\n",
       "      <td>6810.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[carport, community_outdoor_space, corner_lot,...</td>\n",
       "      <td>Best Homes Real Estate</td>\n",
       "      <td>mls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3420-W-Danbury-Dr-Apt-C203_Phoenix_AZ_85053_M2...</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-10-10T00:05:43.000000Z</td>\n",
       "      <td>2023-12-26</td>\n",
       "      <td>190000</td>\n",
       "      <td>186000</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>725.0</td>\n",
       "      <td>751.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[carport, community_outdoor_space, community_s...</td>\n",
       "      <td>Keller Williams Arizona Realty</td>\n",
       "      <td>mls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>65-W-Virginia-Ave_Phoenix_AZ_85003_M21913-18360</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-12-01T16:57:52.000000Z</td>\n",
       "      <td>2023-12-26</td>\n",
       "      <td>650000</td>\n",
       "      <td>675000</td>\n",
       "      <td>1930.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1544.0</td>\n",
       "      <td>6521.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[carport, community_outdoor_space, hardwood_fl...</td>\n",
       "      <td>None</td>\n",
       "      <td>mls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8642-N-Wren-Cir_Phoenix_AZ_85028_M25914-19335</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-11-10T19:09:30.000000Z</td>\n",
       "      <td>2023-12-26</td>\n",
       "      <td>1675000</td>\n",
       "      <td>1701500</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2903.0</td>\n",
       "      <td>37462.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[city_view, community_outdoor_space, cul_de_sa...</td>\n",
       "      <td>None</td>\n",
       "      <td>mls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>17639-N-1st-St_Phoenix_AZ_85022_M17937-36762</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-11-03T23:54:38.000000Z</td>\n",
       "      <td>2023-12-26</td>\n",
       "      <td>549000</td>\n",
       "      <td>525000</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2110.0</td>\n",
       "      <td>12197.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[community_outdoor_space, community_security_f...</td>\n",
       "      <td>None</td>\n",
       "      <td>mls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3720-W-Redfield-Rd_Phoenix_AZ_85053_M11883-14260</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-11-20T16:22:33.000000Z</td>\n",
       "      <td>2023-12-26</td>\n",
       "      <td>385000</td>\n",
       "      <td>385000</td>\n",
       "      <td>1973.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1215.0</td>\n",
       "      <td>8006.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[community_outdoor_space, single_story, garage...</td>\n",
       "      <td>None</td>\n",
       "      <td>mls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2108-E-San-Juan-Ave_Phoenix_AZ_85016_M24297-82422</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-11-09T05:34:32.000000Z</td>\n",
       "      <td>2023-12-26</td>\n",
       "      <td>949900</td>\n",
       "      <td>1038712</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2700.0</td>\n",
       "      <td>11326.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[community_outdoor_space, fireplace, hardwood_...</td>\n",
       "      <td>eXp Realty</td>\n",
       "      <td>mls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8443-S-22nd-St_Phoenix_AZ_85042_M27672-31645</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-11-10T19:36:43.000000Z</td>\n",
       "      <td>2023-12-26</td>\n",
       "      <td>715000</td>\n",
       "      <td>690000</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3135.0</td>\n",
       "      <td>8880.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[community_outdoor_space, family_room, firepla...</td>\n",
       "      <td>Real Broker AZ, LLC</td>\n",
       "      <td>mls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4154-E-Wildwood-Dr_Phoenix_AZ_85048_M29892-98877</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-11-09T18:45:26.000000Z</td>\n",
       "      <td>2023-12-26</td>\n",
       "      <td>499900</td>\n",
       "      <td>498000</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1350.0</td>\n",
       "      <td>5528.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[community_outdoor_space, corner_lot, family_r...</td>\n",
       "      <td>None</td>\n",
       "      <td>mls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1332-E-Wildwood-Dr_Phoenix_AZ_85048_M13759-20461</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-11-07T18:06:24.000000Z</td>\n",
       "      <td>2023-12-26</td>\n",
       "      <td>499900</td>\n",
       "      <td>500000</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1650.0</td>\n",
       "      <td>4696.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[community_outdoor_space, community_security_f...</td>\n",
       "      <td>None</td>\n",
       "      <td>mls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4813-W-Phelps-Rd_Glendale_AZ_85306_M10682-06127</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-08-22T20:43:20.000000Z</td>\n",
       "      <td>2023-12-26</td>\n",
       "      <td>346000</td>\n",
       "      <td>340000</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>8018.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[community_security_features, single_story, ga...</td>\n",
       "      <td>None</td>\n",
       "      <td>mls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1913-E-Atlanta-Ave_Phoenix_AZ_85040_M27579-84281</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-08-30T20:01:25.000000Z</td>\n",
       "      <td>2023-12-26</td>\n",
       "      <td>345000</td>\n",
       "      <td>345000</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1411.0</td>\n",
       "      <td>6887.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[carport, community_security_features, single_...</td>\n",
       "      <td>None</td>\n",
       "      <td>mls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5201-W-Camelback-Rd-Lot-E102_Phoenix_AZ_85031_...</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-09-18T14:34:57.000000Z</td>\n",
       "      <td>2023-12-22</td>\n",
       "      <td>28000</td>\n",
       "      <td>28000</td>\n",
       "      <td>1967.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>768.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[carport, community_clubhouse, community_outdo...</td>\n",
       "      <td>None</td>\n",
       "      <td>mls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>34810-N-23rd-Ln_Phoenix_AZ_85086_M92650-89977</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-11-07T22:33:39.000000Z</td>\n",
       "      <td>2023-12-22</td>\n",
       "      <td>1050000</td>\n",
       "      <td>1010000</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4015.0</td>\n",
       "      <td>14375.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[city_view, community_outdoor_space, community...</td>\n",
       "      <td>None</td>\n",
       "      <td>mls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>919-E-Paseo-Way_Phoenix_AZ_85042_M97984-26880</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-10-19T22:25:49.000000Z</td>\n",
       "      <td>2023-12-22</td>\n",
       "      <td>829890</td>\n",
       "      <td>825000</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3085.0</td>\n",
       "      <td>5751.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[city_view, community_clubhouse, community_out...</td>\n",
       "      <td>None</td>\n",
       "      <td>mls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4746-N-34th-Dr_Phoenix_AZ_85017_M22820-94344</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-11-15T16:42:44.000000Z</td>\n",
       "      <td>2023-12-22</td>\n",
       "      <td>440000</td>\n",
       "      <td>432000</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2155.0</td>\n",
       "      <td>7410.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[community_outdoor_space, swimming_pool, singl...</td>\n",
       "      <td>None</td>\n",
       "      <td>mls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2518-E-Vogel-Ave_Phoenix_AZ_85028_M23924-41948</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-09-25T14:21:41.000000Z</td>\n",
       "      <td>2023-12-22</td>\n",
       "      <td>750000</td>\n",
       "      <td>745000</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>7675.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[community_outdoor_space, community_security_f...</td>\n",
       "      <td>None</td>\n",
       "      <td>mls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>13231-N-Victor-Hugo-Ave_Phoenix_AZ_85032_M2314...</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-11-16T20:04:42.000000Z</td>\n",
       "      <td>2023-12-22</td>\n",
       "      <td>700000</td>\n",
       "      <td>700000</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2202.0</td>\n",
       "      <td>17424.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[community_outdoor_space, hill_or_mountain_vie...</td>\n",
       "      <td>None</td>\n",
       "      <td>mls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3221-N-37th-St-Unit-17_Phoenix_AZ_85018_M27142...</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-08-18T18:08:23.000000Z</td>\n",
       "      <td>2023-12-22</td>\n",
       "      <td>459990</td>\n",
       "      <td>436000</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1418.0</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[fireplace, swimming_pool, single_story, garag...</td>\n",
       "      <td>A.Z. &amp; Associates</td>\n",
       "      <td>mls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>35033-N-12th-St_Phoenix_AZ_85086_M10078-49822</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-11-20T16:22:33.000000Z</td>\n",
       "      <td>2023-12-22</td>\n",
       "      <td>600000</td>\n",
       "      <td>625600</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2136.0</td>\n",
       "      <td>95832.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[single_story, garage_1_or_more, garage_2_or_m...</td>\n",
       "      <td>None</td>\n",
       "      <td>mls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>522-W-Cambridge-Ave_Phoenix_AZ_85003_M22848-55875</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-11-17T16:14:54.000000Z</td>\n",
       "      <td>2023-12-22</td>\n",
       "      <td>825000</td>\n",
       "      <td>827522</td>\n",
       "      <td>1943.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1793.0</td>\n",
       "      <td>8050.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[community_outdoor_space, family_room, firepla...</td>\n",
       "      <td>None</td>\n",
       "      <td>mls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3236-E-Chandler-Blvd-Unit-1081_Phoenix_AZ_8504...</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-11-10T16:21:50.000000Z</td>\n",
       "      <td>2023-12-22</td>\n",
       "      <td>275000</td>\n",
       "      <td>255000</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>1120.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[carport, community_outdoor_space, fireplace, ...</td>\n",
       "      <td>None</td>\n",
       "      <td>mls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1954-E-Grovers-Ave_Phoenix_AZ_85022_M21584-87584</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-12-01T21:03:46.000000Z</td>\n",
       "      <td>2023-12-22</td>\n",
       "      <td>110000</td>\n",
       "      <td>120000</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4353.0</td>\n",
       "      <td>9905.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[carport, fireplace, basement, single_story, g...</td>\n",
       "      <td>HomeSmart</td>\n",
       "      <td>mls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>5237-S-14th-Ave_Phoenix_AZ_85041_M20734-80300</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-06-28T01:07:26.000000Z</td>\n",
       "      <td>2023-12-22</td>\n",
       "      <td>495000</td>\n",
       "      <td>485000</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[investment_opportunity]</td>\n",
       "      <td>None</td>\n",
       "      <td>mls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1568-W-Campbell-Ave_Phoenix_AZ_85015_M16004-51617</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-10-30T14:25:13.000000Z</td>\n",
       "      <td>2023-12-22</td>\n",
       "      <td>267000</td>\n",
       "      <td>267000</td>\n",
       "      <td>1965.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1120.0</td>\n",
       "      <td>1213.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[carport, community_clubhouse, community_outdo...</td>\n",
       "      <td>None</td>\n",
       "      <td>mls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3134-W-McKinley-St_Phoenix_AZ_85009_M20010-61202</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-11-28T19:54:28.000000Z</td>\n",
       "      <td>2023-12-22</td>\n",
       "      <td>175000</td>\n",
       "      <td>180000</td>\n",
       "      <td>1948.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>767.0</td>\n",
       "      <td>7867.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[carport, single_story]</td>\n",
       "      <td>Realty ONE Group</td>\n",
       "      <td>mls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>9821-S-6th-Pl_Phoenix_AZ_85042_M19539-67811</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-11-03T14:57:34.000000Z</td>\n",
       "      <td>2023-12-22</td>\n",
       "      <td>560000</td>\n",
       "      <td>448000</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2176.0</td>\n",
       "      <td>8940.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[hill_or_mountain_view, view, single_story, ga...</td>\n",
       "      <td>My Home Group Real Estate</td>\n",
       "      <td>mls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>19220-N-30th-St_Phoenix_AZ_85050_M21131-39056</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-11-23T22:04:39.000000Z</td>\n",
       "      <td>2023-12-22</td>\n",
       "      <td>524900</td>\n",
       "      <td>540000</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1506.0</td>\n",
       "      <td>13939.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[community_outdoor_space, community_security_f...</td>\n",
       "      <td>None</td>\n",
       "      <td>mls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>29606-N-Tatum-Blvd-Apt-204_Cave-Creek_AZ_85331...</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-11-03T15:46:54.000000Z</td>\n",
       "      <td>2023-12-22</td>\n",
       "      <td>290000</td>\n",
       "      <td>271500</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>858.0</td>\n",
       "      <td>924.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[community_clubhouse, community_outdoor_space,...</td>\n",
       "      <td>None</td>\n",
       "      <td>mls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3924-W-Angela-Dr_Glendale_AZ_85308_M13490-42270</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-11-20T19:06:48.000000Z</td>\n",
       "      <td>2023-12-22</td>\n",
       "      <td>349000</td>\n",
       "      <td>345000</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1564.0</td>\n",
       "      <td>9304.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[community_outdoor_space, corner_lot, single_s...</td>\n",
       "      <td>None</td>\n",
       "      <td>mls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>8049-N-10th-St_Phoenix_AZ_85020_M12739-90588</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-12-07T20:45:42.000000Z</td>\n",
       "      <td>2023-12-22</td>\n",
       "      <td>339900</td>\n",
       "      <td>350000</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1481.0</td>\n",
       "      <td>9118.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[carport, hill_or_mountain_view, view, swimmin...</td>\n",
       "      <td>Launch Powered By Compass</td>\n",
       "      <td>mls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2650-W-Union-Hills-Dr-Lot-84_Phoenix_AZ_85027_...</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-09-18T14:34:57.000000Z</td>\n",
       "      <td>2023-12-22</td>\n",
       "      <td>42000</td>\n",
       "      <td>28000</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1296.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[carport, community_clubhouse, community_outdo...</td>\n",
       "      <td>Simple Realty Professionals</td>\n",
       "      <td>mls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2429-W-Running-Deer-Trl_Phoenix_AZ_85085_M2473...</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-10-30T14:25:13.000000Z</td>\n",
       "      <td>2023-12-22</td>\n",
       "      <td>460000</td>\n",
       "      <td>470000</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1522.0</td>\n",
       "      <td>4499.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[community_outdoor_space, recreation_facilitie...</td>\n",
       "      <td>None</td>\n",
       "      <td>mls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2002-W-Myrtle-Ave_Phoenix_AZ_85021_M27731-84933</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-11-17T21:08:31.000000Z</td>\n",
       "      <td>2023-12-22</td>\n",
       "      <td>389900</td>\n",
       "      <td>389900</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1363.0</td>\n",
       "      <td>7148.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[carport, community_outdoor_space, community_s...</td>\n",
       "      <td>Launch Powered By Compass</td>\n",
       "      <td>mls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2947-E-Tina-Dr_Phoenix_AZ_85050_M12162-99329</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-11-15T22:33:33.000000Z</td>\n",
       "      <td>2023-12-22</td>\n",
       "      <td>1099900</td>\n",
       "      <td>1090000</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3030.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[community_clubhouse, community_outdoor_space,...</td>\n",
       "      <td>None</td>\n",
       "      <td>mls</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            permalink status  \\\n",
       "0    8815-W-Pioneer-St_Tolleson_AZ_85353_M17818-19456   sold   \n",
       "1        2938-N-18th-Pl_Phoenix_AZ_85016_M24990-60512   sold   \n",
       "2     40320-N-Hickok-Ct_Phoenix_AZ_85086_M13341-66678   sold   \n",
       "3     14612-S-1st-St-32_Phoenix_AZ_85048_M22978-80396   sold   \n",
       "4   2323-W-Port-Au-Prince-Ln_Phoenix_AZ_85023_M219...   sold   \n",
       "5   2625-E-Indian-School-Rd-Unit-127_Phoenix_AZ_85...   sold   \n",
       "6   2316-E-Roosevelt-St_Phoenix_AZ_85006_M13012-14169   sold   \n",
       "7       11814-N-31st-Dr_Phoenix_AZ_85029_M15208-82532   sold   \n",
       "8   3420-W-Danbury-Dr-Apt-C203_Phoenix_AZ_85053_M2...   sold   \n",
       "9     65-W-Virginia-Ave_Phoenix_AZ_85003_M21913-18360   sold   \n",
       "10      8642-N-Wren-Cir_Phoenix_AZ_85028_M25914-19335   sold   \n",
       "11       17639-N-1st-St_Phoenix_AZ_85022_M17937-36762   sold   \n",
       "12   3720-W-Redfield-Rd_Phoenix_AZ_85053_M11883-14260   sold   \n",
       "13  2108-E-San-Juan-Ave_Phoenix_AZ_85016_M24297-82422   sold   \n",
       "14       8443-S-22nd-St_Phoenix_AZ_85042_M27672-31645   sold   \n",
       "15   4154-E-Wildwood-Dr_Phoenix_AZ_85048_M29892-98877   sold   \n",
       "16   1332-E-Wildwood-Dr_Phoenix_AZ_85048_M13759-20461   sold   \n",
       "17    4813-W-Phelps-Rd_Glendale_AZ_85306_M10682-06127   sold   \n",
       "18   1913-E-Atlanta-Ave_Phoenix_AZ_85040_M27579-84281   sold   \n",
       "19  5201-W-Camelback-Rd-Lot-E102_Phoenix_AZ_85031_...   sold   \n",
       "20      34810-N-23rd-Ln_Phoenix_AZ_85086_M92650-89977   sold   \n",
       "21      919-E-Paseo-Way_Phoenix_AZ_85042_M97984-26880   sold   \n",
       "22       4746-N-34th-Dr_Phoenix_AZ_85017_M22820-94344   sold   \n",
       "23     2518-E-Vogel-Ave_Phoenix_AZ_85028_M23924-41948   sold   \n",
       "24  13231-N-Victor-Hugo-Ave_Phoenix_AZ_85032_M2314...   sold   \n",
       "25  3221-N-37th-St-Unit-17_Phoenix_AZ_85018_M27142...   sold   \n",
       "26      35033-N-12th-St_Phoenix_AZ_85086_M10078-49822   sold   \n",
       "27  522-W-Cambridge-Ave_Phoenix_AZ_85003_M22848-55875   sold   \n",
       "28  3236-E-Chandler-Blvd-Unit-1081_Phoenix_AZ_8504...   sold   \n",
       "29   1954-E-Grovers-Ave_Phoenix_AZ_85022_M21584-87584   sold   \n",
       "30      5237-S-14th-Ave_Phoenix_AZ_85041_M20734-80300   sold   \n",
       "31  1568-W-Campbell-Ave_Phoenix_AZ_85015_M16004-51617   sold   \n",
       "32   3134-W-McKinley-St_Phoenix_AZ_85009_M20010-61202   sold   \n",
       "33        9821-S-6th-Pl_Phoenix_AZ_85042_M19539-67811   sold   \n",
       "34      19220-N-30th-St_Phoenix_AZ_85050_M21131-39056   sold   \n",
       "35  29606-N-Tatum-Blvd-Apt-204_Cave-Creek_AZ_85331...   sold   \n",
       "36    3924-W-Angela-Dr_Glendale_AZ_85308_M13490-42270   sold   \n",
       "37       8049-N-10th-St_Phoenix_AZ_85020_M12739-90588   sold   \n",
       "38  2650-W-Union-Hills-Dr-Lot-84_Phoenix_AZ_85027_...   sold   \n",
       "39  2429-W-Running-Deer-Trl_Phoenix_AZ_85085_M2473...   sold   \n",
       "40    2002-W-Myrtle-Ave_Phoenix_AZ_85021_M27731-84933   sold   \n",
       "41       2947-E-Tina-Dr_Phoenix_AZ_85050_M12162-99329   sold   \n",
       "\n",
       "                      list_date   sold_date  list_price  sold_price  \\\n",
       "0   2023-12-08T15:08:46.000000Z  2024-01-12      449000      445000   \n",
       "1   2022-02-01T05:25:28.000000Z  2024-01-10      385000      410000   \n",
       "2   2022-06-19T16:36:42.000000Z  2024-01-08     1298000     1206000   \n",
       "3   2017-11-20T03:24:16.000000Z  2024-01-05      375000      330000   \n",
       "4   2023-08-05T22:25:01.000000Z  2023-12-28      429900      415000   \n",
       "5   2023-04-24T22:25:30.000000Z  2023-12-27      214900      200000   \n",
       "6   2023-09-04T13:24:48.000000Z  2023-12-26     2200000     1900000   \n",
       "7   2023-10-30T21:24:41.000000Z  2023-12-26      359900      359900   \n",
       "8   2023-10-10T00:05:43.000000Z  2023-12-26      190000      186000   \n",
       "9   2023-12-01T16:57:52.000000Z  2023-12-26      650000      675000   \n",
       "10  2023-11-10T19:09:30.000000Z  2023-12-26     1675000     1701500   \n",
       "11  2023-11-03T23:54:38.000000Z  2023-12-26      549000      525000   \n",
       "12  2023-11-20T16:22:33.000000Z  2023-12-26      385000      385000   \n",
       "13  2023-11-09T05:34:32.000000Z  2023-12-26      949900     1038712   \n",
       "14  2023-11-10T19:36:43.000000Z  2023-12-26      715000      690000   \n",
       "15  2023-11-09T18:45:26.000000Z  2023-12-26      499900      498000   \n",
       "16  2023-11-07T18:06:24.000000Z  2023-12-26      499900      500000   \n",
       "17  2023-08-22T20:43:20.000000Z  2023-12-26      346000      340000   \n",
       "18  2023-08-30T20:01:25.000000Z  2023-12-26      345000      345000   \n",
       "19  2023-09-18T14:34:57.000000Z  2023-12-22       28000       28000   \n",
       "20  2023-11-07T22:33:39.000000Z  2023-12-22     1050000     1010000   \n",
       "21  2023-10-19T22:25:49.000000Z  2023-12-22      829890      825000   \n",
       "22  2023-11-15T16:42:44.000000Z  2023-12-22      440000      432000   \n",
       "23  2023-09-25T14:21:41.000000Z  2023-12-22      750000      745000   \n",
       "24  2023-11-16T20:04:42.000000Z  2023-12-22      700000      700000   \n",
       "25  2023-08-18T18:08:23.000000Z  2023-12-22      459990      436000   \n",
       "26  2023-11-20T16:22:33.000000Z  2023-12-22      600000      625600   \n",
       "27  2023-11-17T16:14:54.000000Z  2023-12-22      825000      827522   \n",
       "28  2023-11-10T16:21:50.000000Z  2023-12-22      275000      255000   \n",
       "29  2023-12-01T21:03:46.000000Z  2023-12-22      110000      120000   \n",
       "30  2023-06-28T01:07:26.000000Z  2023-12-22      495000      485000   \n",
       "31  2023-10-30T14:25:13.000000Z  2023-12-22      267000      267000   \n",
       "32  2023-11-28T19:54:28.000000Z  2023-12-22      175000      180000   \n",
       "33  2023-11-03T14:57:34.000000Z  2023-12-22      560000      448000   \n",
       "34  2023-11-23T22:04:39.000000Z  2023-12-22      524900      540000   \n",
       "35  2023-11-03T15:46:54.000000Z  2023-12-22      290000      271500   \n",
       "36  2023-11-20T19:06:48.000000Z  2023-12-22      349000      345000   \n",
       "37  2023-12-07T20:45:42.000000Z  2023-12-22      339900      350000   \n",
       "38  2023-09-18T14:34:57.000000Z  2023-12-22       42000       28000   \n",
       "39  2023-10-30T14:25:13.000000Z  2023-12-22      460000      470000   \n",
       "40  2023-11-17T21:08:31.000000Z  2023-12-22      389900      389900   \n",
       "41  2023-11-15T22:33:33.000000Z  2023-12-22     1099900     1090000   \n",
       "\n",
       "    year_built  beds  baths    sqft  lot_sqft  garage  \\\n",
       "0       2011.0   3.0      2  2147.0    5663.0     2.0   \n",
       "1          NaN   NaN      0     NaN    6843.0     NaN   \n",
       "2       2003.0   5.0      5  4408.0   12197.0     3.0   \n",
       "3          NaN   NaN      0     NaN   28314.0     NaN   \n",
       "4       1973.0   3.0      2  1994.0    9344.0     2.0   \n",
       "5       1982.0   1.0      1   655.0     677.0     NaN   \n",
       "6       1949.0   NaN      0     NaN   46035.0     NaN   \n",
       "7       1967.0   3.0      2  1576.0    6810.0     NaN   \n",
       "8       1981.0   1.0      1   725.0     751.0     NaN   \n",
       "9       1930.0   2.0      1  1544.0    6521.0     1.0   \n",
       "10      1977.0   3.0      3  2903.0   37462.0     2.0   \n",
       "11      1980.0   3.0      2  2110.0   12197.0     2.0   \n",
       "12      1973.0   3.0      2  1215.0    8006.0     2.0   \n",
       "13      1955.0   4.0      3  2700.0   11326.0     2.0   \n",
       "14      2005.0   4.0      4  3135.0    8880.0     3.0   \n",
       "15      1993.0   3.0      2  1350.0    5528.0     2.0   \n",
       "16      1993.0   3.0      2  1650.0    4696.0     2.0   \n",
       "17      1979.0   2.0      2  1156.0    8018.0     2.0   \n",
       "18      1956.0   4.0      2  1411.0    6887.0     NaN   \n",
       "19      1967.0   2.0      1   768.0       NaN     NaN   \n",
       "20      2005.0   4.0      4  4015.0   14375.0     3.0   \n",
       "21      2019.0   5.0      4  3085.0    5751.0     3.0   \n",
       "22      1956.0   5.0      2  2155.0    7410.0     NaN   \n",
       "23      1986.0   3.0      3  2800.0    7675.0     2.0   \n",
       "24      1961.0   3.0      3  2202.0   17424.0     2.0   \n",
       "25      2000.0   2.0      3  1418.0    1065.0     2.0   \n",
       "26      1996.0   4.0      3  2136.0   95832.0     2.0   \n",
       "27      1943.0   3.0      2  1793.0    8050.0     2.0   \n",
       "28      1996.0   2.0      1  1019.0    1120.0     NaN   \n",
       "29      2004.0   2.0      2  4353.0    9905.0     1.0   \n",
       "30      1950.0   NaN      0     NaN       NaN     NaN   \n",
       "31      1965.0   2.0      2  1120.0    1213.0     NaN   \n",
       "32      1948.0   2.0      1   767.0    7867.0     NaN   \n",
       "33      2011.0   4.0      2  2176.0    8940.0     3.0   \n",
       "34      1989.0   3.0      2  1506.0   13939.0     2.0   \n",
       "35      1999.0   1.0      1   858.0     924.0     1.0   \n",
       "36      1979.0   3.0      2  1564.0    9304.0     2.0   \n",
       "37      1958.0   3.0      2  1481.0    9118.0     1.0   \n",
       "38      1970.0   2.0      2  1296.0       NaN     NaN   \n",
       "39      2001.0   3.0      2  1522.0    4499.0     2.0   \n",
       "40      1960.0   3.0      2  1363.0    7148.0     NaN   \n",
       "41      2020.0   5.0      5  3030.0    6000.0     2.0   \n",
       "\n",
       "                                                 tags  \\\n",
       "0   [central_air, community_outdoor_space, dishwas...   \n",
       "1                           [cul_de_sac, medicalcare]   \n",
       "2   [community_clubhouse, community_outdoor_space,...   \n",
       "3   [community_security_features, cul_de_sac, hill...   \n",
       "4   [carport, community_outdoor_space, community_s...   \n",
       "5   [carport, community_clubhouse, community_outdo...   \n",
       "6                                 [big_lot, new_roof]   \n",
       "7   [carport, community_outdoor_space, corner_lot,...   \n",
       "8   [carport, community_outdoor_space, community_s...   \n",
       "9   [carport, community_outdoor_space, hardwood_fl...   \n",
       "10  [city_view, community_outdoor_space, cul_de_sa...   \n",
       "11  [community_outdoor_space, community_security_f...   \n",
       "12  [community_outdoor_space, single_story, garage...   \n",
       "13  [community_outdoor_space, fireplace, hardwood_...   \n",
       "14  [community_outdoor_space, family_room, firepla...   \n",
       "15  [community_outdoor_space, corner_lot, family_r...   \n",
       "16  [community_outdoor_space, community_security_f...   \n",
       "17  [community_security_features, single_story, ga...   \n",
       "18  [carport, community_security_features, single_...   \n",
       "19  [carport, community_clubhouse, community_outdo...   \n",
       "20  [city_view, community_outdoor_space, community...   \n",
       "21  [city_view, community_clubhouse, community_out...   \n",
       "22  [community_outdoor_space, swimming_pool, singl...   \n",
       "23  [community_outdoor_space, community_security_f...   \n",
       "24  [community_outdoor_space, hill_or_mountain_vie...   \n",
       "25  [fireplace, swimming_pool, single_story, garag...   \n",
       "26  [single_story, garage_1_or_more, garage_2_or_m...   \n",
       "27  [community_outdoor_space, family_room, firepla...   \n",
       "28  [carport, community_outdoor_space, fireplace, ...   \n",
       "29  [carport, fireplace, basement, single_story, g...   \n",
       "30                           [investment_opportunity]   \n",
       "31  [carport, community_clubhouse, community_outdo...   \n",
       "32                            [carport, single_story]   \n",
       "33  [hill_or_mountain_view, view, single_story, ga...   \n",
       "34  [community_outdoor_space, community_security_f...   \n",
       "35  [community_clubhouse, community_outdoor_space,...   \n",
       "36  [community_outdoor_space, corner_lot, single_s...   \n",
       "37  [carport, hill_or_mountain_view, view, swimmin...   \n",
       "38  [carport, community_clubhouse, community_outdo...   \n",
       "39  [community_outdoor_space, recreation_facilitie...   \n",
       "40  [carport, community_outdoor_space, community_s...   \n",
       "41  [community_clubhouse, community_outdoor_space,...   \n",
       "\n",
       "                              office_name source_type  \n",
       "0                                    None         mls  \n",
       "1                                    None         mls  \n",
       "2               My Home Group Real Estate         mls  \n",
       "3   Keller Williams Realty Sonoran Living         mls  \n",
       "4           Cooper Premier Properties LLC         mls  \n",
       "5                     Nouveau Real Estate         mls  \n",
       "6                                    None         mls  \n",
       "7                  Best Homes Real Estate         mls  \n",
       "8          Keller Williams Arizona Realty         mls  \n",
       "9                                    None         mls  \n",
       "10                                   None         mls  \n",
       "11                                   None         mls  \n",
       "12                                   None         mls  \n",
       "13                             eXp Realty         mls  \n",
       "14                    Real Broker AZ, LLC         mls  \n",
       "15                                   None         mls  \n",
       "16                                   None         mls  \n",
       "17                                   None         mls  \n",
       "18                                   None         mls  \n",
       "19                                   None         mls  \n",
       "20                                   None         mls  \n",
       "21                                   None         mls  \n",
       "22                                   None         mls  \n",
       "23                                   None         mls  \n",
       "24                                   None         mls  \n",
       "25                      A.Z. & Associates         mls  \n",
       "26                                   None         mls  \n",
       "27                                   None         mls  \n",
       "28                                   None         mls  \n",
       "29                              HomeSmart         mls  \n",
       "30                                   None         mls  \n",
       "31                                   None         mls  \n",
       "32                       Realty ONE Group         mls  \n",
       "33              My Home Group Real Estate         mls  \n",
       "34                                   None         mls  \n",
       "35                                   None         mls  \n",
       "36                                   None         mls  \n",
       "37              Launch Powered By Compass         mls  \n",
       "38            Simple Realty Professionals         mls  \n",
       "39                                   None         mls  \n",
       "40              Launch Powered By Compass         mls  \n",
       "41                                   None         mls  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the extracted information into a DataFrame\n",
    "pd.DataFrame(extracted_info)\n",
    "\n",
    "#write a function to take a list of lists and then unique counts of each element in the list..counter python collections "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Good MVP will have data from one city and use that to create a function that can be applied to all cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the fact that with tags, there are a lot of categorical variables.\n",
    "- How many columns would we have if we OHE tags, city and state?\n",
    "- Perhaps we can get rid of tags that have a low frequency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which features have least Nan values \n",
    "Then automated values and every other city only botehrs with those featyres "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data = []\n",
    "# for file_name in ['file_1.json', 'file_2.json']:  # extend this list to include all your files\n",
    "#     with open(file_name) as f:\n",
    "#         data = json.load(f)\n",
    "#         # Assuming your data extraction is for lists of records\n",
    "#         for record in data.get('key_of_interest', []):  # This retrieves your list of records or an empty list if the key doesn't exist\n",
    "#             extracted_info = extract_info(record)\n",
    "#             all_data.append(extracted_info)\n",
    "\n",
    "# # Convert to DataFrame\n",
    "# df = pd.DataFrame(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OHE categorical variables here\n",
    "# tags will have to be done manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sales will vary drastically between cities and states.  Is there a way to keep information about which city it is without OHE such as using central tendency?\n",
    "- Could we label encode or ordinal encode?  Yes, but this may have undesirable effects, giving nominal data ordinal values.\n",
    "- If you replace cities or states with numerical values, make sure that the data is split so that we don't leak data into the training selection. This is a great time to train test split. Compute on the training data, and join these values to the test data\n",
    "- Drop columns that aren't needed.\n",
    "- Don't keep the list price because it will be too close to the sale price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform train test split here\n",
    "# do something with state and city\n",
    "# drop any other not needed columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STRETCH**\n",
    "\n",
    "- You're not limited to just using the data provided to you. Think/ do some research about other features that might be useful to predict housing prices. \n",
    "- Can you import and join this data? Make sure you do any necessary preprocessing and make sure it is joined correctly.\n",
    "- Example suggestion: could mortgage interest rates in the year of the listing affect the price? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import, join and preprocess new data here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember all of the EDA that you've been learning about?  Now is a perfect time for it!\n",
    "- Look at distributions of numerical variables to see the shape of the data and detect outliers.\n",
    "- Scatterplots of a numerical variable and the target go a long way to show correlations.\n",
    "- A heatmap will help detect highly correlated features, and we don't want these.\n",
    "- Is there any overlap in any of the features? (redundant information, like number of this or that room...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform EDA here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now is a great time to scale the data and save it once it's preprocessed.\n",
    "- You can save it in your data folder, but you may want to make a new `processed/` subfolder to keep it organized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
